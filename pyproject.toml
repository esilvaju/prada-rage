[tool.poetry]
name = "prada-rage"
version = "0.1.0"
description = ""
authors = ["maany <imptodefeat@gmail.com>"]
readme = "README.md"
packages = [{include = "lib"}]

[tool.poetry.dependencies]
python = "^3.9"
dependency-injector = "^4.41.0"
python-dotenv = "^1.0.0"
pyyaml = "^6.0.1"
googlesearch-python = "^1.2.3"
beautifulsoup4 = "^4.12.2"
requests = "^2.31.0"
langchain = "^0.0.259"
chromadb = "^0.4.5"
llama-cpp-python = "^0.1.77"
pdfminer-six = "^20221105"
instructorembedding = "^1.0.1"
sentence-transformers = "^2.2.2"
huggingface-hub = "^0.16.4"
transformers = "^4.31.0"
faiss-cpu = "^1.7.4"
torch = ">=2.0.0, !=2.0.1"
auto-gptq = "0.2.2"


[tool.poetry.group.dev.dependencies]
pytest = "^7.4.0"
pytest-cov = "^4.1.0"
ipykernel = "^6.25.0"
pytest-env = "^0.8.2"

[tool.pytest.ini_options]
env = [
    "PRADA_RAGE_ROOT_DIRECTORY=./tests/mocks",
    "PRADA_RAGE_SOURCE_DOCS_DIR=source_docs",
    "PRADA_RAGE_DB_DIR=db",
    "PRADA_RAGE_ANONYMIZED_TELEMETRY=false",
    "PRADA_RAGE_EMBEDDING_MODEL_NAME=hkunlp/instructor-large",
    "PRADA_RAGE_EMBEDDING_DEVICE_TYPE=cpu",
    "PRADA_RAGE_EMBEDDING_CHUNK_SIZE=1000",
    "PRADA_RAGE_EMBEDDING_CHUNK_OVERLAP=200",
    "PRADA_RAGE_LOCALGPT_LLM_MODEL=llama2-7b-chat",
    "PRADA_RAGE_ELASTIC_HOST=localhost",
    "PRADA_RAGE_ELASTIC_PORT=9200",
    "PRADA_RAGE_ELASTIC_INDEX=rage",
    "PRADA_RAGE_ELASTIC_USER=elastic",
    "PRADA_RAGE_ELASTIC_PASSWORD=changeme",
]

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
