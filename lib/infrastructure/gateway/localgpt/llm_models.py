supported_models = {
    "vicuna-7b": {
        "model_id": "TheBloke/vicuna-7B-1.1-HF",
        "model_basename": None,
        "type": "hf",
    },
    "Vicuna-7B-Uncensored": {
        "model_id": "TheBloke/Wizard-Vicuna-7B-Uncensored-HF",
        "model_basename": None,
        "type": "hf",
    },
    "guanaco-7b": {
        "model_id": "TheBloke/guanaco-7B-HF",
        "model_basename": None,
        "type": "hf",
    },
    "nous-hermes-13b": {
        "model_id": "TheBloke/Nous-Hermes-13B-GPTQ",
        "model_basename": "nous-hermes-13b-GPTQ-4bit-128g.no-act.order",
        "type": "gptq",
    },
    "WizardLM-30B-Uncensored": {
        "model_id": "TheBloke/WizardLM-30B-Uncensored-GPTQ",
        "model_basename": "WizardLM-30B-Uncensored-GPTQ-4bit.act-order.safetensors",
        "type": "gptq",
    },
    "wizardLM-7B": {
        "model_id": "TheBloke/wizardLM-7B-GPTQ",
        "model_basename": "wizardLM-7B-GPTQ-4bit.compat.no-act-order.safetensors",
        "type": "gptq",
    },
    "WizardLM-7B-uncensored": {
        "model_id": "TheBloke/WizardLM-7B-uncensored-GPTQ",
        "model_basename": "WizardLM-7B-uncensored-GPTQ-4bit-128g.compat.no-act-order.safetensors",
        "type": "gptq",
    },
    "wizard-vicuna-13B": {
        "model_id": "TheBloke/wizard-vicuna-13B-GGML",
        "model_basename": "wizard-vicuna-13B.ggmlv3.q4_0.bin",
        "type": "ggml",
    },
    "orca-mini-3B": {
        "model_id": "TheBloke/orca_mini_3B-GGML",
        "model_basename": "orca-mini-3b.ggmlv3.q4_0.bin",
        "type": "ggml",
    },
    "llama2-7b-chat": {
        "model_id": "TheBloke/Llama-2-7B-Chat-GGML",
        "model_basename": "llama-2-7b-chat.ggmlv3.q4_0.bin",
    },
}
